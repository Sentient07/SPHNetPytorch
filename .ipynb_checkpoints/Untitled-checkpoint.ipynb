{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1f95c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "import os.path as osp\n",
    "\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import PointNetWithSPH\n",
    "from modelnet_dataset import ModelNet40Generator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6954adc1",
   "metadata": {},
   "source": [
    "## Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60291f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model params\n",
    "out_channels = (64, 256, 1024)\n",
    "kernel_radius = 1.0*np.array([0.4*0.25, 0.4*0.5, 0.4*1., 1.])\n",
    "strides = [0]*3\n",
    "nr = 2\n",
    "l_max = 3\n",
    "normalize_patches = False\n",
    "patch_size = 64\n",
    "pool_ratio = 4\n",
    "nlatent = 1024\n",
    "\n",
    "# Data params\n",
    "data_dir = '/mnt/disk1/datasets/modelnet40_ply_hdf5_2048'\n",
    "train_file = 'train_files.txt'\n",
    "test_file = 'test_files.txt'\n",
    "\n",
    "# Training params\n",
    "n_epoch = 200\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db18c1f8",
   "metadata": {},
   "source": [
    "## Define and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1a7a5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/datasets/modelnet40_ply_hdf5_2048/ply_data_train0.h5\n",
      "/mnt/disk1/datasets/modelnet40_ply_hdf5_2048/ply_data_train1.h5\n",
      "/mnt/disk1/datasets/modelnet40_ply_hdf5_2048/ply_data_train2.h5\n",
      "/mnt/disk1/datasets/modelnet40_ply_hdf5_2048/ply_data_train3.h5\n",
      "/mnt/disk1/datasets/modelnet40_ply_hdf5_2048/ply_data_train4.h5\n",
      "/mnt/disk1/datasets/modelnet40_ply_hdf5_2048/ply_data_test0.h5\n",
      "/mnt/disk1/datasets/modelnet40_ply_hdf5_2048/ply_data_test1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-673a94df419a>:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for n_e in tqdm(range(n_epoch)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1e3da1151548ddbdeaa7dd1fbf56f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.360953\n",
      "Test Accuracy : 0.189529\n",
      "Train Accuracy : 0.484528\n",
      "Test Accuracy : 0.262175\n",
      "Train Accuracy : 0.505090\n",
      "Test Accuracy : 0.211039\n",
      "Train Accuracy : 0.528705\n",
      "Test Accuracy : 0.261769\n",
      "Train Accuracy : 0.551812\n",
      "Test Accuracy : 0.246753\n",
      "Train Accuracy : 0.561482\n",
      "Test Accuracy : 0.241071\n",
      "Train Accuracy : 0.580415\n",
      "Test Accuracy : 0.290990\n",
      "Train Accuracy : 0.594564\n",
      "Test Accuracy : 0.308847\n",
      "Train Accuracy : 0.606678\n",
      "Test Accuracy : 0.362825\n",
      "Train Accuracy : 0.609629\n",
      "Test Accuracy : 0.334821\n",
      "Train Accuracy : 0.615330\n",
      "Test Accuracy : 0.318588\n",
      "Train Accuracy : 0.624593\n",
      "Test Accuracy : 0.299513\n",
      "Train Accuracy : 0.632227\n",
      "Test Accuracy : 0.338880\n",
      "Train Accuracy : 0.636604\n",
      "Test Accuracy : 0.338474\n",
      "Train Accuracy : 0.635077\n",
      "Test Accuracy : 0.307630\n",
      "Train Accuracy : 0.643119\n",
      "Test Accuracy : 0.359984\n",
      "Train Accuracy : 0.642203\n",
      "Test Accuracy : 0.334821\n",
      "Train Accuracy : 0.653909\n",
      "Test Accuracy : 0.375812\n",
      "Train Accuracy : 0.653807\n",
      "Test Accuracy : 0.326705\n",
      "Train Accuracy : 0.661340\n",
      "Test Accuracy : 0.335633\n",
      "Train Accuracy : 0.659711\n",
      "Test Accuracy : 0.328328\n",
      "Train Accuracy : 0.664292\n",
      "Test Accuracy : 0.373782\n",
      "Train Accuracy : 0.664699\n",
      "Test Accuracy : 0.374594\n",
      "Train Accuracy : 0.667752\n",
      "Test Accuracy : 0.395698\n",
      "Train Accuracy : 0.671213\n",
      "Test Accuracy : 0.355925\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = PointNetWithSPH(out_channels, kernel_radius, strides, l_max, nr, patch_size,\n",
    "                        pool_ratio, nlatent)\n",
    "model = model.cuda().float()\n",
    "# Dataset and loader\n",
    "train_dataset = ModelNet40Generator('train', data_dir, train_file)\n",
    "test_dataset = ModelNet40Generator('test', data_dir, test_file)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=16, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=16, drop_last=True)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "cat_loss = nn.NLLLoss()\n",
    "\n",
    "train_loss_epoch, test_loss_epoch, train_acc_epoch, test_acc_epoch = [], [], [], []\n",
    "\n",
    "for n_e in tqdm(range(n_epoch)):\n",
    "    model.train()\n",
    "    train_loss_iter, test_loss_iter, test_acc_iter, train_acc_iter = [], [], [], []\n",
    "    for X, Y in train_loader:\n",
    "        X = X.cuda().float()\n",
    "        Y = Y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(X)\n",
    "        cur_loss = cat_loss(prediction, torch.argmax(Y, axis=1))\n",
    "        l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "        cur_loss += 1e-3*l2_norm\n",
    "        cur_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_iter.append(cur_loss.item())\n",
    "        train_acc = torch.sum(torch.exp(prediction).argmax(axis=1) == Y.argmax(axis=1))/int(prediction.shape[0])\n",
    "        train_acc_iter.append(train_acc.item())\n",
    "        \n",
    "    for X, Y in test_loader:\n",
    "        X = X.cuda().float()\n",
    "        Y = Y.cuda()\n",
    "        model.eval()\n",
    "        prediction = model(X)\n",
    "        cur_loss = cat_loss(prediction, torch.argmax(Y, axis=1))\n",
    "        test_loss_iter.append(cur_loss.item())\n",
    "        test_acc = torch.sum(torch.exp(prediction).argmax(axis=1) == Y.argmax(axis=1))/int(prediction.shape[0])\n",
    "        test_acc_iter.append(test_acc.item())\n",
    "        \n",
    "    train_loss_epoch.append(np.mean(train_loss_iter))\n",
    "    test_loss_epoch.append(np.mean(test_loss_iter))\n",
    "\n",
    "    train_acc_epoch.append(np.mean(train_acc_iter ))\n",
    "    test_acc_epoch.append(np.mean(test_acc_iter))\n",
    "    \n",
    "    \n",
    "#     print(\"Train loss : %f\" %train_loss_epoch[-1])\n",
    "    print(\"Train Accuracy : %f\" %train_acc_epoch[-1])\n",
    "#     print(\"Test loss : %f\" %test_loss_epoch[-1])\n",
    "    print(\"Test Accuracy : %f\" %test_acc_epoch[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1917e317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch.nn.functional as F\n",
    "\n",
    "rand_np = torch.load('X_.pth').cpu().numpy()\n",
    "rand_torch = torch.from_numpy(rand_np).float()\n",
    "rand_tf = tf.constant(rand_np)\n",
    "eps = 1e-4\n",
    "\n",
    "x_norm_torch = F.normalize(rand_torch, p=2, dim=-1, eps=np.sqrt(eps))\n",
    "x_norm_tf = tf.nn.l2_normalize(rand_tf, axis=-1, epsilon=eps)\n",
    "\n",
    "\n",
    "norm_custom = rand_torch/torch.norm(rand_torch, p=2, dim=-1, keepdim=True)\n",
    "# norm_custom[torch.isnan(norm_custom)] = 0 # to avoid nan\n",
    "\n",
    "np.max(x_norm_tf.numpy()-x_norm_torch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff5ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.title(\"ModelNet O/A\")\n",
    "# plt.plot(np.arange(len(test_acc_epoch)), test_acc_epoch, label='Test acc')\n",
    "# plt.plot(np.arange(len(train_acc_epoch)), train_acc_epoch, label='Train acc')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.legend(loc='best')\n",
    "# plt.show()\n",
    "Y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
